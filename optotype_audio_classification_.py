# -*- coding: utf-8 -*-
"""Optotype Audio Classification .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ic2U816zOBAmLR4bSEF3mb2F4Y6Njajk
"""

import pandas as pd
import numpy as np
import os
import seaborn as sns
import matplotlib.pyplot as plt
import librosa
import librosa.display
from IPython.display import Audio
import sklearn

from google.colab import drive
drive.mount('/content/drive')

data_path = '/content/drive/MyDrive/Report-audios'

data = pd.DataFrame(columns=['label', 'path'])

for label in os.listdir(data_path):
    label_path = os.path.join(data_path, label)
    for filename in os.listdir(label_path):
        if filename.endswith('.wav'):
            filepath = os.path.join(label_path, filename)
            data = data.append({'label': label, 'path': filepath}, ignore_index=True)

data.to_csv('audio_data.csv', index=False)

df = pd.read_csv('audio_data.csv')
df.head()

df['label'].value_counts()

def waveplot(data,sr,optotype):
  plt.figure(figsize=(10,4))
  plt.title(optotype,size=20)
  librosa.display.waveplot(data,sr=sr)
  plt.show()

optotype = 'O'
path = np.array(df['path'][df['label']==optotype])[33]
data, sampling_rate = librosa.load(path)
plt.figure(figsize=(10,4))
plt.title(optotype,size=20)
plt.plot(data)
plt.show()
Audio(path)

mfccs=librosa.feature.mfcc(y=data, sr=sampling_rate,n_mfcc=40)
print(mfccs.shape)

mfccs

##Deploying CNN Model

max_pad_len = 85


X_mfcc = []
label1 = []

def extract_mfcc(file_name):
    audio, sample_rate = librosa.load(file_name) 
    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)
    pad_width = max_pad_len - mfccs.shape[1]
    mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')
    mfccs = (mfccs - np.mean(mfccs)) / np.std(mfccs)

    return mfccs

X_mfcc = []
label1 = []

for i in range(len(df)):
    x = extract_mfcc(df['path'][i])
    X_mfcc.append(x)
    y = df['label'][i]
    label1.append(y)

X_mfcc

extracted_features_df= pd.DataFrame({'features': X_mfcc, 'class': label1})

extracted_features_df.head(187)

X=np.array(extracted_features_df['features'].tolist())
Y=np.array(extracted_features_df['class'].tolist())

X.shape

### Label Encoding
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import LabelEncoder
labelencoder=LabelEncoder()
Y=to_categorical(labelencoder.fit_transform(Y))

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 42)

from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D
from keras.optimizers import Adam
from keras.utils import np_utils
from sklearn import metrics 

num_rows = 40
num_columns = 85
num_channels = 1

x_train = X_train.reshape(X_train.shape[0], num_rows, num_columns, num_channels)
x_test = X_test.reshape(X_test.shape[0], num_rows, num_columns, num_channels)

num_labels = 4

# Construct model 
model = Sequential()
model.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))
model.add(MaxPooling2D(pool_size=2))
model.add(Dropout(0.2))

model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))
model.add(MaxPooling2D(pool_size=2))
model.add(Dropout(0.2))

model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))
model.add(MaxPooling2D(pool_size=2))
model.add(Dropout(0.2))

model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))
model.add(MaxPooling2D(pool_size=2))
model.add(Dropout(0.2))


model.add(Flatten())

model.add(Dense(64, activation='relu'))
model.add(Dense(num_labels, activation='softmax'))

model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')

# Display model architecture summary 
model.summary()

import matplotlib.pyplot as plt

num_epochs = 100
num_batch_size = 32

history = model.fit(X_train, Y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, Y_test))

train_loss = history.history['loss']
test_loss = history.history['val_loss']
train_accuracy = history.history['accuracy']
test_accuracy = history.history['val_accuracy']

plt.figure(figsize=(10, 6))
plt.plot(range(1, num_epochs + 1), train_loss, label='Training Loss')
plt.plot(range(1, num_epochs + 1), test_loss, label='Test Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss vs Test Loss')
plt.legend()
plt.ylim(bottom=0)  # Set y-axis to start from 0
plt.show()

# Plot training accuracy and test accuracy
plt.figure(figsize=(10, 6))
plt.plot(range(1, num_epochs + 1), train_accuracy, label='Training Accuracy')
plt.plot(range(1, num_epochs + 1), test_accuracy, label='Test Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training Accuracy vs Test Accuracy')
plt.legend()
plt.ylim(bottom=0)  # Set y-axis to start from 0
plt.show()

# Evaluating the model on the training and testing set
score = model.evaluate(X_train, Y_train)
print("Training Accuracy: ", score[1])

score = model.evaluate(X_test, Y_test)
print("Testing Accuracy: ", score[1])

def print_prediction(file_name):
    prediction_feature = extract_mfcc(file_name) 
    prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)
    predicted_vector = np.argmax(model.predict(prediction_feature),axis=-1)
    predicted_class = labelencoder.inverse_transform(predicted_vector) 
    predicted_class
    print("The predicted class is:", predicted_class[0], '\n')

filename = 'F_TEST.wav' 
print_prediction(filename)

filename = 'Z_test.wav' 
print_prediction(filename)

filename = 'O_test.wav' 
print_prediction(filename)

filename = 'L2test (2).wav' 
print_prediction(filename)

